{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def get_block_group_population(census_gdf, census_api_key, year, output_file, csv_output_file, aggregate_file):\n",
    "    \"\"\"\n",
    "    Retrieves population data for block groups based on a given year and saves the processed data to a file.\n",
    "\n",
    "    Parameters:\n",
    "        census_gdf (GeoDataFrame): The GeoDataFrame containing the geometries for the census block groups.\n",
    "        census_api_key (str): The Census API key.\n",
    "        year (int): The year for which the data is retrieved (e.g., 2013, 2017, 2022).\n",
    "        output_file (str): The filename where the processed data will be saved.\n",
    "        csv_output_file (str): The filename for saving the processed CSV data.\n",
    "        aggregate_file (str): The filename for appending population density data.\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame: The processed GeoDataFrame with population and PDI data.\n",
    "    \"\"\"\n",
    "    # Check if the API key is provided\n",
    "    if not census_api_key:\n",
    "        raise ValueError(\"API key must be provided as the 'census_api_key' parameter.\")\n",
    "\n",
    "    # Get unique state and county FIPS codes from the GeoDataFrame\n",
    "    state_fips = census_gdf.STATEFP.unique()[0]\n",
    "    county_fips = census_gdf.COUNTYFP.unique()\n",
    "\n",
    "    census_pop = []\n",
    "\n",
    "    # Retrieve census data by block group for the specified state and county\n",
    "    for county_fip in county_fips:\n",
    "        params = {\n",
    "            'get': 'B01003_001E',\n",
    "            'for': 'block group:*',\n",
    "            'in': f'state:{state_fips} county:{county_fip}',\n",
    "            'key': census_api_key\n",
    "        }\n",
    "        url = f'https://api.census.gov/data/{year}/acs/acs5'\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            columns = data[0]\n",
    "            values = data[1:]\n",
    "            df = pd.DataFrame(values, columns=columns)\n",
    "            census_pop.append(df)\n",
    "        else:\n",
    "            print(f\"Error fetching data for county {county_fip}: {response.text}\")\n",
    "            continue\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    if census_pop:\n",
    "        census_pop_df = pd.concat(census_pop, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No data retrieved from the Census API.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Data retrieved from the Census API (first few rows):\\n{census_pop_df}\")\n",
    "\n",
    "    # Rename columns in census_gdf to match the names in census_pop_df\n",
    "    census_gdf.rename(columns={\n",
    "        'STATEFP': 'state',\n",
    "        'COUNTYFP': 'county',\n",
    "        'TRACTCE': 'tract',\n",
    "        'BLKGRPCE': 'block group',\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Ensure that 'state', 'county', 'tract', 'block group' are strings and zero-padded as necessary\n",
    "    census_gdf['state'] = census_gdf['state'].astype(str).str.zfill(2)\n",
    "    census_gdf['county'] = census_gdf['county'].astype(str).str.zfill(3)\n",
    "    census_gdf['tract'] = census_gdf['tract'].astype(str).str.zfill(6)\n",
    "    census_gdf['block group'] = census_gdf['block group'].astype(str).str.zfill(1)  # Block group is typically one digit\n",
    "\n",
    "    # Similarly for census_pop_df\n",
    "    census_pop_df['state'] = census_pop_df['state'].astype(str).str.zfill(2)\n",
    "    census_pop_df['county'] = census_pop_df['county'].astype(str).str.zfill(3)\n",
    "    census_pop_df['tract'] = census_pop_df['tract'].astype(str).str.zfill(6)\n",
    "    census_pop_df['block group'] = census_pop_df['block group'].astype(str).str.zfill(1)\n",
    "    census_pop_df['B01003_001E'] = pd.to_numeric(census_pop_df['B01003_001E'], errors='coerce')\n",
    "\n",
    "    # Merge census_gdf with the population DataFrame on 'state', 'county', 'tract', 'block group'\n",
    "    merged_gdf = census_gdf.merge(census_pop_df[['state', 'county', 'tract', 'block group', 'B01003_001E']], on=['state', 'county', 'tract', 'block group'], how='left')\n",
    "\n",
    "    # Continue with the rest of the code\n",
    "    # Rename the population column to something more user-friendly\n",
    "    merged_gdf.rename(columns={'B01003_001E': 'Population Count'}, inplace=True)\n",
    "\n",
    "    # Create the 'GEOID' column\n",
    "    merged_gdf['GEOID'] = merged_gdf['state'] + merged_gdf['county'] + merged_gdf['tract'] + merged_gdf['block group']\n",
    "\n",
    "    # Calculate area in square kilometers\n",
    "    area_sqkm = merged_gdf['ALAND'] / 10**6\n",
    "    merged_gdf['Polygon Area'] = area_sqkm\n",
    "\n",
    "    # Calculate population density\n",
    "    merged_gdf['Population Density'] = merged_gdf['Population Count'] / area_sqkm\n",
    "\n",
    "    # Calculate PDI (Population Density Index) as a percentage of the max density\n",
    "    max_density = merged_gdf['Population Density'].max() if not merged_gdf['Population Density'].isna().all() else 1\n",
    "    merged_gdf['PDI'] = (merged_gdf['Population Density'] / max_density) * 100  # PDI as percentage of max, ranging from 0 to 100\n",
    "\n",
    "    # Ensure that merged_gdf has a valid geometry\n",
    "    merged_gdf = gpd.GeoDataFrame(merged_gdf, geometry='geometry')\n",
    "\n",
    "    # Calculate centroids and extract coordinates\n",
    "    merged_gdf['Centroid'] = merged_gdf.geometry.centroid\n",
    "    merged_gdf['Coordinates'] = merged_gdf['Centroid'].apply(lambda x: f\"({x.y:.6f}, {x.x:.6f})\")\n",
    "\n",
    "    # Drop the Centroid column before saving to GeoJSON\n",
    "    merged_gdf = merged_gdf.drop(columns=['Centroid'])\n",
    "\n",
    "    # Save processed data to GeoJSON\n",
    "    merged_gdf.to_file(output_file, driver=\"GeoJSON\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "    # Prepare CSV output with specified column names and order\n",
    "    csv_output = merged_gdf[['GEOID', 'Population Count', 'Population Density', 'PDI', 'Polygon Area', 'Coordinates']]\n",
    "    csv_output.to_csv(csv_output_file, index=False)\n",
    "    print(f\"CSV data saved to {csv_output_file}\")\n",
    "    \n",
    "    # Append population density to aggregate file\n",
    "    geoidandyear = merged_gdf[\"GEOID\"] + \"+\" + str(year)\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Population Density\": merged_gdf[\"Population Density\"]\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode='w', header=True, index=False)\n",
    "\n",
    "    return merged_gdf\n",
    "\n",
    "# Block Group execution\n",
    "\n",
    "census_api_key = \"bb8ddb8b99dc18f4759d67d905c25e1486077c4d\"  # Replace with your actual Census API key\n",
    "\n",
    "# Ensure you have year-specific GeoJSON files for block groups\n",
    "census_gdf_2013 = gpd.read_file('block_groups.geojson')\n",
    "census_gdf_2013 = get_block_group_population(\n",
    "    census_gdf_2013, year=2013, census_api_key=census_api_key,\n",
    "    output_file=\"block_groups_2013_PDI.geojson\",\n",
    "    csv_output_file=\"block_groups_2013_PDI.csv\",\n",
    "    aggregate_file=\"PDI_bg_all.csv\"\n",
    ")\n",
    "\n",
    "census_gdf_2017 = gpd.read_file('block_groups.geojson')\n",
    "census_gdf_2017 = get_block_group_population(\n",
    "    census_gdf_2017, year=2017, census_api_key=census_api_key,\n",
    "    output_file=\"block_groups_2017_PDI.geojson\",\n",
    "    csv_output_file=\"block_groups_2017_PDI.csv\",\n",
    "    aggregate_file=\"PDI_bg_all.csv\"\n",
    ")\n",
    "\n",
    "census_gdf_2022 = gpd.read_file('block_groups.geojson')\n",
    "census_gdf_2022 = get_block_group_population(\n",
    "    census_gdf_2022, year=2022, census_api_key=census_api_key,\n",
    "    output_file=\"block_groups_2022_PDI.geojson\",\n",
    "    csv_output_file=\"block_groups_2022_PDI.csv\",\n",
    "    aggregate_file=\"PDI_bg_all.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
