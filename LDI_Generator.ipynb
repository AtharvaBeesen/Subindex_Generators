{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, LineString, mapping\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6be900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to fetch data from Overpass API for a polygon and a specific year\n",
    "def fetch_landuse_data(polygon, year):\n",
    "    print(f\"fetching for year {year}\")\n",
    "    polygon = gpd.GeoSeries([polygon], crs=\"EPSG:3857\").to_crs(epsg=4326).iloc[0]\n",
    "    bounds = polygon.bounds  # (minx, miny, maxx, maxy)\n",
    "    bbox = f\"{bounds[1]},{bounds[0]},{bounds[3]},{bounds[2]}\"\n",
    "    query = f\"\"\"\n",
    "    [out:json][date:\"{year}-01-01T00:00:00Z\"];\n",
    "    (\n",
    "      way[\"landuse\"]({bbox});\n",
    "      relation[\"landuse\"]({bbox});\n",
    "    );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://overpass-api.de/api/interpreter\", params={'data': query}, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Overpass API request failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate LDI for a given GeoJSON input, year, and output prefix\n",
    "def calculate_ldi(input_geojson, output_prefix, year, aggregate_file):\n",
    "    # Load GeoJSON data\n",
    "    data = gpd.read_file(input_geojson)\n",
    "\n",
    "    # Initialize storage for entropy and land use dictionaries\n",
    "    entropies = []\n",
    "    landuse_dictionaries = []\n",
    "\n",
    "    # Reproject to EPSG:3857 for area calculations\n",
    "    data = data.to_crs(epsg=3857)\n",
    "\n",
    "    for idx, polygon in enumerate(data.geometry):\n",
    "        try:\n",
    "            # Fetch land use data\n",
    "            landuse_data = fetch_landuse_data(polygon, year)\n",
    "            if not landuse_data or 'elements' not in landuse_data:\n",
    "                entropies.append(0)\n",
    "                landuse_dictionaries.append({})\n",
    "                continue\n",
    "\n",
    "            # Process geometries and land use types\n",
    "            geometries = []\n",
    "            landuse_types = []\n",
    "            for element in landuse_data['elements']:\n",
    "                if 'geometry' in element:\n",
    "                    coords = [(pt['lon'], pt['lat']) for pt in element['geometry']]\n",
    "                    if len(coords) < 3:\n",
    "                        geometries.append(LineString(coords))\n",
    "                    else:\n",
    "                        geometries.append(Polygon(coords))\n",
    "                    landuse_types.append(element['tags'].get('landuse', ''))\n",
    "\n",
    "            # Create GeoDataFrame for land use types\n",
    "            gdf = gpd.GeoDataFrame({'landuse': landuse_types, 'geometry': geometries}, crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "            gdf[\"area\"] = gdf.geometry.area\n",
    "\n",
    "            # Aggregate area by land use type\n",
    "            landuse_area_dict = gdf.groupby('landuse')['area'].sum().to_dict()\n",
    "            landuse_dictionaries.append(landuse_area_dict)\n",
    "\n",
    "            # Filter and calculate entropy\n",
    "            valid_landuse_dict = {k: v for k, v in landuse_area_dict.items() if v > 0}\n",
    "            total_area = sum(valid_landuse_dict.values())\n",
    "            k = len(valid_landuse_dict)\n",
    "\n",
    "            if k > 1 and total_area > 0:\n",
    "                denominator = np.log(k)\n",
    "                numerator = -sum((v / total_area) * np.log(v / total_area) for v in valid_landuse_dict.values())\n",
    "                entropies.append(numerator / denominator)\n",
    "            else:\n",
    "                entropies.append(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing polygon {idx + 1}: {e}\")\n",
    "            entropies.append(0)\n",
    "            landuse_dictionaries.append({})\n",
    "\n",
    "    # Calculate LDI\n",
    "    max_entropy = max(entropies) if entropies else 0\n",
    "    ldis = [e / max_entropy if max_entropy else 0 for e in entropies]\n",
    "\n",
    "    # Add fields to GeoDataFrame\n",
    "    data[\"Entropy\"] = entropies\n",
    "    data[\"LDI\"] = [0] * len(data)  # Placeholder field for 'LDI'\n",
    "    data[\"Coordinates\"] = data.geometry.apply(lambda geom: mapping(geom)[\"coordinates\"])\n",
    "    data['Polygon Area'] = data.geometry.area\n",
    "\n",
    "    # Convert back to EPSG:4326 for output\n",
    "    data = data.to_crs(epsg=4326)\n",
    "\n",
    "    columns_to_keep = [\"GEOID\", \"Entropy\", \"LDI\", \"Polygon Area\", \"Coordinates\", \"geometry\"]\n",
    "    data = data[columns_to_keep]\n",
    "    \n",
    "    geoidandyear = data[\"GEOID\"] + \"+\" + str(year)\n",
    "    # Append to aggregate file\n",
    "    aggregate_df = pd.DataFrame({\n",
    "        \"GEOID\": geoidandyear,\n",
    "        \"Entropy\": data[\"Entropy\"]\n",
    "    })\n",
    "    if os.path.exists(aggregate_file):\n",
    "        aggregate_df.to_csv(aggregate_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        aggregate_df.to_csv(aggregate_file, mode='w', header=True, index=False)\n",
    "\n",
    "    # Save outputs as GeoJSON and CSV\n",
    "    geojson_file = f\"{output_prefix}_{year}_LDI.geojson\"\n",
    "    csv_file = f\"{output_prefix}_{year}_LDI.csv\"\n",
    "    data.to_file(geojson_file, driver=\"GeoJSON\")\n",
    "    data.drop(columns=\"geometry\").to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Processed {year}. Outputs saved to '{geojson_file}' and '{csv_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census BG\n",
    "calculate_ldi(\n",
    "    input_geojson=\"block_groups.geojson\",  # Replace with your census bg GeoJSON file\n",
    "    output_prefix=\"block_groups\",\n",
    "    year=2013,\n",
    "    aggregate_file=\"LDI_bg_all.csv\"\n",
    ")\n",
    "calculate_ldi(\n",
    "    input_geojson=\"block_groups.geojson\",  # Replace with your census bg GeoJSON file\n",
    "    output_prefix=\"block_groups\",\n",
    "    year=2017,\n",
    "    aggregate_file=\"LDI_bg_all.csv\"\n",
    ")\n",
    "calculate_ldi(\n",
    "    input_geojson=\"block_groups.geojson\",  # Replace with your census bg GeoJSON file\n",
    "    output_prefix=\"block_groups\",\n",
    "    year=2022,\n",
    "    aggregate_file=\"LDI_bg_all.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
